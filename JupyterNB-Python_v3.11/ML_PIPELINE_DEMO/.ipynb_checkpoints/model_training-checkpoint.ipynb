{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9820bb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "from scipy.stats import shapiro, kstest, norm, probplot, chi2_contingency\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, log_loss, mean_squared_error,confusion_matrix, precision_score, recall_score, auc,roc_curve, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import configparser\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b056e9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def open_config_file(config_file):\n",
    "    \"\"\"Opens the configuration file for user review.\"\"\"\n",
    "    if not os.path.exists(config_file):\n",
    "        print(f\"Configuration file '{config_file}' not found.\")\n",
    "        return False\n",
    "    try:\n",
    "        if os.name == 'nt':  # Windows\n",
    "            os.startfile(config_file)\n",
    "        else:\n",
    "            subprocess.Popen(['open' if os.name == 'posix' else 'xdg-open', config_file])\n",
    "        input(\"Press Enter once you've reviewed the configuration file...\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to open the configuration file: {e}\")\n",
    "        return False\n",
    "\n",
    "def load_model_params(config_file, model_name):\n",
    "    \"\"\"Loads model parameters from the configuration file.\"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_file)\n",
    "    params = {}\n",
    "    for key, value in config[model_name].items():\n",
    "        try:\n",
    "            params[key] = eval(value)  # Evaluate values for literals\n",
    "        except (NameError, SyntaxError):\n",
    "            params[key] = value.strip(\"'\\\"\")\n",
    "    return params\n",
    "\n",
    "def load_paths_and_suffix(config_file):\n",
    "    \"\"\"Loads input/output paths and suffix from the configuration file.\"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_file)\n",
    "    return {\n",
    "        \"input_folder\": config[\"Paths\"].get(\"input_folder\", \"../OTH_DATA/cleaned_data\"),\n",
    "        \"output_folder\": config[\"Paths\"].get(\"output_folder\", \"../ML_DATA/model_outputs\"),\n",
    "        \"model_name_suffix\": config[\"Paths\"].get(\"model_name_suffix\", \"_v1\"),\n",
    "    }\n",
    "\n",
    "def select_training_file(input_folder):\n",
    "    \"\"\"Prompts user to select a training file from the input folder.\"\"\"\n",
    "    files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
    "    if not files:\n",
    "        print(\"No CSV files found in the specified folder.\")\n",
    "        return None\n",
    "    print(\"Available files for training:\")\n",
    "    for idx, file in enumerate(files, 1):\n",
    "        print(f\"{idx}. {file}\")\n",
    "    try:\n",
    "        choice = int(input(\"Select the file number to use for training: \")) - 1\n",
    "        return os.path.join(input_folder, files[choice])\n",
    "    except (ValueError, IndexError):\n",
    "        print(\"Invalid selection.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_models(config_file):\n",
    "    \"\"\"Allows the user to select models to train.\"\"\"\n",
    "    all_models = {\n",
    "        \"RandomForest\": RandomForestClassifier(**load_model_params(config_file, \"RandomForest\")),\n",
    "        \"AdaBoost\": AdaBoostClassifier(**load_model_params(config_file, \"AdaBoost\")),\n",
    "        \"GradientBoosting\": GradientBoostingClassifier(**load_model_params(config_file, \"GradientBoosting\")),\n",
    "        \"KNeighbors\": KNeighborsClassifier(**load_model_params(config_file, \"KNeighbors\")),\n",
    "        \"SVC\": SVC(**load_model_params(config_file, \"SVC\")),\n",
    "        \"DecisionTree\": DecisionTreeClassifier(**load_model_params(config_file, \"DecisionTree\")),\n",
    "        \"LogisticRegression\": LogisticRegression(**load_model_params(config_file, \"LogisticRegression\")),\n",
    "        \"NaiveBayes\": GaussianNB(**load_model_params(config_file, \"NaiveBayes\")),\n",
    "        \"NeuralNetwork\": MLPClassifier(**load_model_params(config_file, \"NeuralNetwork\")),\n",
    "        \"XGBoost\": XGBClassifier(**load_model_params(config_file, \"XGBoost\")),\n",
    "    }\n",
    "    print(\"Available models:\")\n",
    "    for idx, model_name in enumerate(all_models, 1):\n",
    "        print(f\"{idx}. {model_name}\")\n",
    "    selection = input(\"Enter the model numbers to train (comma-separated) or 'all': \")\n",
    "    if selection.lower() == 'all':\n",
    "        return all_models\n",
    "    else:\n",
    "        indices = [int(i.strip()) - 1 for i in selection.split(\",\")]\n",
    "        return {model_name: model for idx, (model_name, model) in enumerate(all_models.items()) if idx in indices}\n",
    "\n",
    "def train_and_save_models(X, y, paths, models):\n",
    "    \"\"\"Trains and saves selected models.\"\"\"\n",
    "    os.makedirs(paths[\"output_folder\"], exist_ok=True)\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ])\n",
    "    for model_name, model in models.items():\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model),\n",
    "        ])\n",
    "        pipeline.fit(X, y)\n",
    "        model_path = os.path.join(paths[\"output_folder\"], f\"{model_name}{paths['model_name_suffix']}.pkl\")\n",
    "        joblib.dump(pipeline, model_path)\n",
    "        print(f\"Saved model: {model_name} to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197bbf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(data):\n",
    "    print(\"Available features:\")\n",
    "    for idx, column in enumerate(data.columns):\n",
    "        print(f\"{idx + 1}: {column}\")\n",
    "    selected = input(\"Enter the feature numbers to use (comma-separated), type 'all' to select all, or press Enter for default (2,3,4,5,6): \")\n",
    "    \n",
    "    if selected.lower() == 'all':\n",
    "        return data\n",
    "    elif selected.strip() == '':  # Default option if no input\n",
    "        default_indices = [1, 2, 3, 4, 5]  # 2,3,4,5,6 are indices 1,2,3,4,5 (0-based)\n",
    "        return data.iloc[:, default_indices]\n",
    "    else:\n",
    "        selected_indices = [int(i) - 1 for i in selected.split(',')]\n",
    "        return data.iloc[:, selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a11d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(data):\n",
    "    print(\"\\nAvailable features for normalization:\")\n",
    "    for idx, column in enumerate(data.columns):\n",
    "        print(f\"{idx + 1}: {column}\")\n",
    "    normalize = input(\"Enter the feature numbers to normalize (comma-separated) or press Enter to skip: \")\n",
    "    \n",
    "    if normalize:\n",
    "        selected_indices = [int(i) - 1 for i in normalize.split(',')]\n",
    "        selected_features = data.columns[selected_indices]\n",
    "        for feature in selected_features:\n",
    "            data[feature] = np.log1p(data[feature]) # Log transformation\n",
    "            print(f\"Applied log transformation on {feature}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe257d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_training_file(input_folder):\n",
    "    files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
    "    if not files:\n",
    "        print(\"No CSV files found in the specified input folder.\")\n",
    "        return None\n",
    "    print(\"Available files for model training:\")\n",
    "    for idx, file in enumerate(files, 1):\n",
    "        print(f\"{idx}. {file}\")\n",
    "    choice = int(input(\"Select the file number to use for training: \")) - 1\n",
    "    return os.path.join(input_folder, files[choice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f517237",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"../SCRIPTS_CFG/config.txt\"\n",
    "if not open_config_file(config_file):\n",
    "    print(\"Exiting due to missing or inaccessible config file.\")\n",
    "\n",
    "else:\n",
    "    # Load paths and model name suffix\n",
    "    paths = load_paths_and_suffix(config_file)\n",
    "\n",
    "    # List files in the input folder and prompt user to select one\n",
    "    data_path = select_training_file(paths[\"input_folder\"])\n",
    "    if data_path is None:\n",
    "        print(\"No valid file selected. Exiting.\")\n",
    "\n",
    "    else:\n",
    "        data = pd.read_csv(data_path)\n",
    "\n",
    "        # Select features\n",
    "        data = select_features(data)\n",
    "\n",
    "        # Separate features and target variable\n",
    "        # target_col = input(\"Enter the target column (label) by name for training (e.g., 'Survived'): \")\n",
    "        target_col = \"Obesity_Level\"\n",
    "        if target_col not in data.columns:\n",
    "            raise ValueError(f\"The specified target column '{target_col}' does not exist in the data.\")\n",
    "\n",
    "        X = data.drop(columns=[target_col])\n",
    "        y = data[target_col]\n",
    "\n",
    "        # Select models to train\n",
    "        models = select_models(config_file)\n",
    "\n",
    "        # Normalize features if needed\n",
    "        X = normalize_features(X)\n",
    "\n",
    "        # Train and save models\n",
    "        train_and_save_models(X, y, paths, models)\n",
    "        print(\"Training completed and models saved.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser(description=\"Train various models on a selected dataset.\")\n",
    "#     parser.add_argument('--config_file', type=str, default=\"config.txt\", help=\"Path to the model parameter file.\")\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "#     main(args.config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4610d2a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
